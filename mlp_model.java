class MLPClassifier {

    private enum Activation { IDENTITY, LOGISTIC, RELU, TANH, SOFTMAX }

    private Activation hidden;
    private Activation output;
    private double[][] network;
    private double[][][] weights;
    private double[][] bias;

    public MLPClassifier(String hidden, String output, int[] layers, double[][][] weights, double[][] bias) {
        this.hidden = Activation.valueOf(hidden.toUpperCase());
        this.output = Activation.valueOf(output.toUpperCase());
        this.network = new double[layers.length + 1][];
        for (int i = 0, l = layers.length; i < l; i++) {
            this.network[i + 1] = new double[layers[i]];
        }
        this.weights = weights;
        this.bias = bias;
    }

    public MLPClassifier(String hidden, String output, int neurons, double[][][] weights, double[][] bias) {
        this(hidden, output, new int[] { neurons }, weights, bias);
    }

    private double[] compute(Activation activation, double[] v) {
        switch (activation) {
            case LOGISTIC:
                for (int i = 0, l = v.length; i < l; i++) {
                    v[i] = 1. / (1. + Math.exp(-v[i]));
                }
                break;
            case RELU:
                for (int i = 0, l = v.length; i < l; i++) {
                    v[i] = Math.max(0, v[i]);
                }
                break;
            case TANH:
                for (int i = 0, l = v.length; i < l; i++) {
                    v[i] = Math.tanh(v[i]);
                }
                break;
            case SOFTMAX:
                double max = Double.NEGATIVE_INFINITY;
                for (double x : v) {
                    if (x > max) {
                        max = x;
                    }
                }
                for (int i = 0, l = v.length; i < l; i++) {
                    v[i] = Math.exp(v[i] - max);
                }
                double sum = 0.;
                for (double x : v) {
                    sum += x;
                }
                for (int i = 0, l = v.length; i < l; i++) {
                    v[i] /= sum;
                }
                break;
        }
        return v;
    }

    public int predict(double[] neurons) {
        this.network[0] = neurons;

        for (int i = 0; i < this.network.length - 1; i++) {
            for (int j = 0; j < this.network[i + 1].length; j++) {
                for (int l = 0; l < this.network[i].length; l++) {
                    this.network[i + 1][j] += this.network[i][l] * this.weights[i][l][j];
                }
                this.network[i + 1][j] += this.bias[i][j];
            }
            if ((i + 1) < (this.network.length - 1)) {
                this.network[i + 1] = this.compute(this.hidden, this.network[i + 1]);
            }
        }
        this.network[this.network.length - 1] = this.compute(this.output, this.network[this.network.length - 1]);

        if (this.network[this.network.length - 1].length == 1) {
            if (this.network[this.network.length - 1][0] > .5) {
                return 1;
            }
            return 0;
        } else {
            int classIdx = 0;
            for (int i = 0; i < this.network[this.network.length - 1].length; i++) {
                classIdx = this.network[this.network.length - 1][i] > this.network[this.network.length - 1][classIdx] ? i : classIdx;
            }
            return classIdx;
        }

    }

    public static void main(String[] args) {
        if (args.length == 4) {

            // Features:
            double[] features = new double[args.length];
            for (int i = 0, l = args.length; i < l; i++) {
                features[i] = Double.parseDouble(args[i]);
            }

            // Parameters:
            int[] layers = {40, 4, 2, 3};
            double[][][] weights = {{{0.09400758037196595, 0.09872987471338568, -0.6966431960692274, -0.19388096811166322, 0.7301731286542799, 0.0342059102158849, 3.143201697996197, -0.05342373311590883, 2.1470700471836017, 0.3033732166663647, 0.16034390951349256, 0.07116493718254983, -0.5317276510614268, 0.029114945887869115, 0.5167434498005113, 0.6942001722164445, -0.10346841435635619, 0.07166481431557449, 0.18683564103600803, 0.8006616564108674, 0.7357888524526923, 0.11613823977211261, -0.11107331346783963, 0.13099454596166188, -0.14857498028224578, 0.1411196658546339, 0.6370388540458559, 2.2978316243486634, -0.1660946955613614, 0.03735280637805941, 0.30535517935714834, -0.0009059271424563379, -0.01477981174955471, 0.06933014525049418, 0.3013340387037355, -0.5223959893095271, -0.6156790744607281, 11.268408863508999, -0.5786280033635723, 0.02575083918657342}, {0.09636263063121288, -0.18289875466266758, 0.6519223647696007, -0.0013389644804255175, 2.631636715128117, 0.2705738794888694, 5.868465086605485, 0.07152584184938876, -0.5360009081595717, 0.3239129054896041, -0.0232103785702416, 1.025315742658157, -0.5936203870175913, 0.14422058737845983, 0.3669393037734576, 0.7511499300680856, -0.07288988150530451, -0.3001263880473901, 0.1523192405720307, 1.165926507921898, 0.8453859355831623, 0.0993260185073335, -0.30058049121889524, 0.05285710844615271, 0.1190826750138155, 0.09349307274318454, 0.0859480624574591, 0.71687002940825, -0.16821176276437338, -0.09512948526928522, 0.4016858407550005, 0.22934467065943165, 0.00575998985002532, 0.06966000050278158, 0.08538133193522762, -0.5340474927430771, -0.37096033453193106, -15.906053476933057, -0.011116780868756889, 0.8825182163346603}, {-0.2311295624630384, 0.29346791392297567, -1.8957451797641345, 0.03921957058709913, -0.6061358914109838, 0.17029426888639454, -6.7023657461660635, -0.11188410218926875, 2.8281718115450305, -0.328406584355675, -0.18401444088859636, -1.327047869503378, -0.1301181736807337, -0.21608212474782887, 0.08937788291744893, -0.19147893351347609, 0.1147615929457022, 0.5333624309902472, 0.029869176804535803, -0.5197414258551118, 0.35825564408393895, -0.11174072180747352, 0.6231606306308544, 0.09518916017238442, -0.34311144867295446, -0.08799690825293786, 0.6084762045407829, 1.64155914588677, 0.23543166302575544, 0.42129964016156457, 0.13693373121374533, -0.172630467911425, 0.5848861142388482, -0.29450830820496365, -0.023086990441594644, -0.01955917099407563, -0.5514589210552855, -4.3961419497910965, -0.960491672289375, -0.9731638041256341}, {-0.07893187378690669, 0.08784793972700822, -1.0304620834876728, 0.03166424174958757, 0.6319283906492534, 0.08660362499121561, -6.858442235240861, -0.23622648038147348, 1.0992796014075856, 0.08166139886993283, -0.07040828838916245, -0.7406119127164521, 0.1347261007302871, -0.20458911146220904, -0.044841649373467435, -0.047712898301663156, 0.05811997740081352, 0.5113859386298117, 0.1827917259231301, 0.40469714073972385, 0.22547910466345705, -0.28852296209804085, 0.2656984267166812, 0.20465974581947097, -0.02576960360633884, -0.1471367464083119, 0.17837512943189548, 0.6279155752232576, -0.050500002146414494, 0.4827826838202596, 0.23226757937152787, -0.0022884307708666927, 0.3753200702606646, -0.0056872233798871425, -0.10775397981132452, -0.15137923184633312, -0.36274182657424886, -10.05153595304862, -0.4803349612337683, -0.3941560747946233}}, {{-0.12212582619256632, 0.10641912604889124, -0.5045937376840948, 0.1707187589577542}, {-0.5136091034574943, -1.0512446946089073, 0.3862632548724561, -0.030402308358937695}, {0.42702458606183663, 0.11208204667563519, -3.0154092585789067, 0.10865102706712082}, {-0.005802146715318705, -0.13504347349531431, -0.18119994824785535, -0.11638357452770533}, {2.4489368796571287, -0.05253795069923589, -1.1091208717901624, 0.13220803925767885}, {-0.5691025592773551, -1.1837558863893753, 0.05593985593067018, -0.03995129596389788}, {13.053052746370458, -0.4536824601891127, -0.260938036878327, -0.16747449733364925}, {0.07800558727125556, 0.08297052727941477, -0.45593464540957707, 0.060684074304657554}, {-1.3679170626824657, -1.1766400005166375, 2.176396138805474, 0.016941719969137257}, {-0.15994869770011833, 0.16067190170377962, -0.7581197362905137, -0.11533925043872356}, {0.04931951176351413, 0.10410477046169658, -0.47306016541880713, -0.13177659141534523}, {0.030751400346824297, -0.006657473894206313, -2.5533367404865164, -0.032569481695568184}, {-0.371965744586522, -1.1070823241587744, 0.44764593288141885, -0.1575166422881729}, {-0.13028914475241876, 0.1697983961373918, -0.5685073935333514, 0.1571253731793721}, {-0.43894197431563164, -1.137410510081419, 0.08800650109045546, -0.04571129038687507}, {-0.6146027388062658, -0.826399742513196, 0.11702011395045811, 0.02489250828128404}, {-0.1307039827769579, -0.059680178885285935, -0.17853023116856467, -0.14189539271004253}, {-0.4281419527636375, -1.2062060085802793, 0.9649917813105272, -0.16528762782004222}, {-0.592372926627212, -1.0283169991938483, 0.017891543260368528, 0.020499910680372078}, {0.05764316886560083, -0.8344202555628516, -0.20783471484943772, 0.10151378445038652}, {-0.9382938719228707, -0.8105626702351142, 0.544059609199257, 0.04417363788179245}, {0.11965546633011245, 0.13020838219509762, -0.44883177751557196, -0.0016706297074420226}, {-0.22797694167644184, -1.168302725092217, 0.8563197577835974, -0.21750145662569967}, {-0.5908044394606269, -0.9837548715457376, 0.17328837361207491, 0.036014340712566706}, {0.09992491734538277, 0.1013160007853218, -0.37600500025916866, -0.050720144246941344}, {-0.08104692390570174, 0.18787119441809294, -0.42556063858257476, -0.12593349249676325}, {-0.47545810863149435, -1.2303050865906229, -0.041747053261758114, -0.15814145037656377}, {-0.7935338868606878, -1.2777014477893396, 1.6594968225093263, -0.12662129173033296}, {-0.13125840599384694, 0.14575790833796984, 0.05568668534274455, -0.13340819922400493}, {-0.4468902670133337, -1.1506710904283206, 0.5601732307463907, 0.05261880857138276}, {-0.49586751966431475, -1.057800083919904, -0.033646666462967295, -0.12119236160474134}, {-0.19725932017155945, -0.05759002332206242, -0.4990770158860466, -0.16334079941980528}, {-0.6008780114243347, -1.1167029244827598, 0.3927823812962743, 0.0463256985169708}, {0.04804354685018229, 0.1518345574621296, -0.3118329564457708, -0.16262131658813808}, {-0.49067391127589555, -1.0171506010314848, 0.11563735517633397, -0.10760942234263457}, {-0.07669444156925628, -1.079967910690775, -0.048071029590712584, -0.17689911847283987}, {-0.04243312857521476, -0.0053140930941743365, 0.1368183296239415, 0.0016920012974093752}, {6.104284150823013, 0.5939809408619966, -0.31868051780611817, -0.07407696558771588}, {0.15446918801781798, -0.04896908042829358, -0.09280788943153484, -0.1085800366570498}, {0.18890756027543898, 0.11862006293960169, -1.5315770302393106, -0.08406572585755134}}, {{-3.616179725239016, 10.484895271960161}, {-7.369755558625438, -1.6355467860580966}, {11.77057024383574, -4.150001331493437}, {0.45973783140941094, 0.1365103884962801}}, {{-13.510288057924239, 11.118638281744365, 2.9858678461932087}, {13.926776929207962, -0.16056966590988256, -14.271392572128368}}};
            double[][] bias = {{-0.12110701075888769, -0.04987105796426213, -0.01627349771244713, -0.14959929979138595, 0.04006339064123525, 0.17008949580457125, 8.043823564525901, -0.15163618680409605, -0.0042101529483973485, 0.25106172666475185, 0.18484665348568904, 0.06743037765492463, -0.1494301281469149, 0.0562016652079489, 0.17124614273487598, 0.4006071195265849, -0.062150998231593195, -0.24219820640428968, 0.2176446494352552, 0.3025634437321666, 0.24455765015913666, 0.09154332013235361, -0.16141436719633298, 0.06432012367086169, 0.16036509841115862, 0.19873853256492605, 0.2664199909210743, 0.4263634107376237, -0.11264323701835181, -0.08012329672976475, 0.08327456927179958, 0.11182365036189455, -0.12044845200540429, 0.1570353260962844, 0.021033780302800967, 0.08618812553739054, -0.06122414005493964, 6.699900353240587, -0.11405679058823841, 0.0817765574510525}, {-0.7057921778236856, -1.2287692269300545, -0.05502126980439821, -0.07237187518288854}, {-4.623065435440333, -3.573792811830317}, {-5.774249471666118, -2.9060409710938635, 8.816471586809755}};

            // Prediction:
            MLPClassifier clf = new MLPClassifier("logistic", "softmax", layers, weights, bias);
            int estimation = clf.predict(features);
            System.out.println(estimation);

        }
    }
}